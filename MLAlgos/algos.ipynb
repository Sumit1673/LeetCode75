{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN:\n",
    "\n",
    "* Supervised learning: Requires labeled data, where each data point has a corresponding class label.\n",
    "* Goal: Classifies a new data point based on the labels of its nearest neighbors in the training data.\n",
    "* Applications: Spam filtering, handwriting recognition, image classification.\n",
    "* Algorithm: Finds the k nearest neighbors (data points) in the training set for a new data point and assigns the most frequent class label among those neighbors.\n",
    "* Output: Class label for a new, unseen data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class KNN:\n",
    "    # Find the labels of the new data points based on the labels of its nearest neighbors\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Store training data. \"\"\"\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Predict classes for test points.\"\"\"\n",
    "        predictions = []\n",
    "        for x_test in X_test:\n",
    "            #1. Find the distance bw new point and all the points\n",
    "            #np.linalg.norm(xt - x_test) default order is 2 i.e. Euclidean distance\n",
    "            distances = [np.linalg.norm(xt - x_test) for xt in self.X_train]\n",
    "            #2. Find k nearest points \n",
    "            k_indices = np.argsort(distances)[: self.k]  # Indices of k nearest neighbors\n",
    "            #3. Get their labels\n",
    "            k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "            #4. Select the label that is most common in k nearest neghbors\n",
    "            most_common_label = Counter(k_nearest_labels).most_common(1)[0][0]\n",
    "            predictions.append(most_common_label)\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Sample Dataset\n",
    "X = np.array([[2, 3],\n",
    "              [5, 4],\n",
    "              [9, 6],\n",
    "              [4, 7],\n",
    "              [8, 1],\n",
    "              [7, 2]])\n",
    "y = np.array([0, 0, 1, 1, 0, 0])  # Labels: 0 or 1\n",
    "\n",
    "# Create KNN classifier (let's use k = 3)\n",
    "clf = KNN(k=3)\n",
    "\n",
    "# Fit the model with our sample data\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Test points for prediction\n",
    "test_points = np.array([[3, 4.5], [6, 5]])\n",
    "\n",
    "# Make predictions\n",
    "predictions = clf.predict(test_points)\n",
    "print(predictions) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering:\n",
    "\n",
    "* Unsupervised learning: Deals with unlabeled data, where data points don't have predefined categories.\n",
    "* Goal: Groups similar data points together based on their features or characteristics.\n",
    "* Applications: Customer segmentation, anomaly detection, image compression.\n",
    "* Common algorithms: K-Means, Hierarchical clustering, DBSCAN.\n",
    "* Output: Clusters (groups) of data points with similar features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label : [1]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class KMeans2:\n",
    "    def __init__(self, n_clusters, n_epochs=20) -> None:\n",
    "        self.n_clusters = n_clusters\n",
    "        self.iters = n_epochs\n",
    "\n",
    "    def __initialize_centroids(self, data):\n",
    "        ### Using random centroids as a starting point from the data points itself\n",
    "        return np.array(random.sample(list(data), self.n_clusters))\n",
    "    \n",
    "    def __calculate_distance(self, data, centroids):\n",
    "        # Euclidean Distance\n",
    "        distances = np.sqrt(((data - centroids[:, np.newaxis])**2).sum(axis=2))\n",
    "        return distances\n",
    "    \n",
    "    def _find_closest_centroids(self, X, centroids):\n",
    "        # lets say n_centroids are 4 and 6 data points, then shape of the distance is n_centroid x n_points --> \n",
    "        # n_centroid[0][0] --> distance between point 1 and centroid 1\n",
    "        # n_centroid[1][0] --> distance between point 1 and centroid 2 .... \n",
    "        # when you take argmin along axis=0(rows), so min value along all the row is taken \n",
    "        distances = self.__calculate_distance(X, centroids)\n",
    "        return np.argmin(distances, axis=0)\n",
    "\n",
    "    def _update_centroids(self, labels, X):\n",
    "        \"\"\"Compute new centroid positions as the mean of points within a cluster.\"\"\"\n",
    "        centroids = np.zeros((self.n_clusters, X.shape[1]))\n",
    "\n",
    "        for k in range(self.n_clusters):\n",
    "            centroids[k, :] = np.mean(X[labels==k, :], axis=0)\n",
    "        \n",
    "        return centroids\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.centroids = self.__initialize_centroids(X)\n",
    "\n",
    "        for _ in range(self.iters):\n",
    "            initial_centroids = self.centroids\n",
    "            labels = self._find_closest_centroids(X, self.centroids)\n",
    "            new_centroids = self._update_centroids(labels, X)\n",
    "            self.centroids = new_centroids\n",
    "            \n",
    "            # Check for convergence\n",
    "            if np.all(self.centroids == initial_centroids):\n",
    "                break\n",
    "\n",
    "    def predict(self, test_point):\n",
    "        return f\"Label : {self._find_closest_centroids(test_point, self.centroids)}\"\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# 1. We need Data\n",
    "# 2. A class that takes k clusters and no. of iterations as an input.\n",
    "## 2.a Function that initializes the centroid --> using the data points\n",
    "## 2.b A function that calculates the distance between the data points and the centroid and points closest to the centroid\n",
    "###    are grouped together\n",
    "### 2.c a function that performs all above functions --> fit\n",
    "\n",
    "# Sample Dataset \n",
    "X = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6], [9, 11]])\n",
    "\n",
    "# Create K-Means model (let's use k = 2)\n",
    "kmeans = KMeans2(n_clusters=2)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Predict cluster for a new point\n",
    "new_point = [10, 9]\n",
    "cluster_label = kmeans.predict([new_point]) \n",
    "print(cluster_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
